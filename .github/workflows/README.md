# GitHub Actions CI/CD Pipeline

This document explains the continuous integration and deployment pipeline for the PulseWatch project.

## Overview

The CI/CD pipeline runs automatically on every push and pull request to ensure code quality, correctness, and security.

## Pipeline Structure

```
CI Pipeline
├── Lint Job (Python 3.12)
│   ├── Black (code formatting)
│   ├── isort (import sorting)
│   ├── Flake8 (linting)
│   ├── MyPy (type checking)
│   └── Bandit (security)
│
├── Test Job (Python 3.11, 3.12)
│   ├── Service: MySQL 8.0
│   ├── Service: Redis 7
│   ├── Run migrations
│   ├── Run pytest with coverage
│   └── Upload coverage reports
│
├── Docker Job
│   ├── Build Docker image
│   ├── Verify build succeeds
│   └── Test image runs
│
├── Security Job
│   ├── Dependency vulnerability scan
│   └── Comprehensive pre-commit checks
│
└── CI Success (requires all above)
```

## Jobs

### 1. Lint Job

**Purpose**: Enforce code quality standards

**Runs on**: Python 3.12

**Checks**:
- **Black**: Code formatting (line length: 100)
- **isort**: Import statement sorting
- **Flake8**: PEP 8 compliance and code smells
- **MyPy**: Type checking (currently non-blocking)
- **Bandit**: Security vulnerability scanning (currently non-blocking)

**Duration**: ~2-3 minutes

**Failure conditions**:
- Code not formatted with Black
- Imports not sorted correctly
- Flake8 violations

### 2. Test Job

**Purpose**: Verify functionality and maintain test coverage

**Runs on**: Python 3.11 and 3.12 (matrix strategy)

**Services**:
- **MySQL 8.0**: Database for integration tests
- **Redis 7**: Cache for integration tests

**Steps**:
1. Set up Python environment
2. Install dependencies from `requirements/dev.txt`
3. Wait for MySQL and Redis to be healthy
4. Configure test environment (`.env` file)
5. Run database migrations
6. Execute test suite with pytest
7. Generate coverage reports (XML, HTML, terminal)
8. Upload coverage artifacts (Python 3.12 only)

**Coverage requirements**:
- Minimum: 80% code coverage
- Target: 85%+

**Duration**: ~5-8 minutes per Python version

**Failure conditions**:
- Any test fails
- Coverage below 80%
- Database connection errors

### 3. Docker Job

**Purpose**: Verify Docker image builds correctly

**Runs on**: Ubuntu latest

**Steps**:
1. Set up Docker Buildx
2. Build Docker image with caching
3. Verify Python version in container
4. Verify Django installation in container

**Duration**: ~3-5 minutes

**Failure conditions**:
- Docker build fails
- Image doesn't run
- Python or Django not available

### 4. Security Job

**Purpose**: Identify security vulnerabilities

**Runs on**: Python 3.12

**Checks**:
- **Safety**: Dependency vulnerability scanning
- **Pre-commit (CI config)**: Comprehensive checks including secrets detection

**Duration**: ~3-4 minutes

**Note**: Currently non-blocking (continue-on-error: true)

### 5. CI Success Job

**Purpose**: Gate for branch protection

**Depends on**: lint, test, docker jobs

**Result**:
- ✅ Success if all required jobs pass
- ❌ Failure if any required job fails

This job is used for branch protection rules.

## Triggers

### Push Events

Pipeline runs on push to:
- `main` branch
- `develop` branch
- `feature/**` branches
- `001-project-bootstrap` branch

### Pull Request Events

Pipeline runs on pull requests targeting:
- `main` branch
- `develop` branch

## Environment Variables

```yaml
PYTHON_VERSION: '3.12'      # Default Python version
POETRY_VERSION: '1.7.0'     # Poetry version (reserved for future use)
```

### Test Environment

Tests run with the following configuration:
```bash
DATABASE_URL=mysql://pulsewatch:pulsewatch@127.0.0.1:3306/pulsewatch_test
REDIS_URL=redis://127.0.0.1:6379/0
SECRET_KEY=test-secret-key-for-ci-testing-only-not-for-production
DEBUG=False
DJANGO_SETTINGS_MODULE=core.settings.test
```

## Artifacts

### Coverage Reports

**Generated by**: Test job (Python 3.12)

**Contents**:
- `htmlcov/` - HTML coverage report
- `coverage.xml` - XML coverage report for external tools

**Retention**: 30 days

**Access**: GitHub Actions → Workflow run → Artifacts section

### Codecov Integration

Coverage reports are automatically uploaded to Codecov (if configured).

**Note**: Upload failures don't fail the build (continue-on-error: true)

## Caching

### Pip Cache

Python dependencies are cached using `actions/setup-python` with `cache: 'pip'`.

**Cache key**: Based on `requirements/dev.txt` hash

**Benefit**: ~1-2 minute faster dependency installation

### Docker Cache

Docker layers are cached using GitHub Actions cache.

**Cache type**: `type=gha` (GitHub Actions cache backend)

**Benefit**: ~2-3 minute faster Docker builds on cache hits

## Running CI Checks Locally

### Full Check (Recommended before pushing)

```bash
make check
```

This runs:
- Linting (black, isort, flake8, mypy)
- Full test suite with coverage

### Individual Checks

```bash
# Formatting
make format              # Auto-fix formatting issues
make lint                # Check only (don't fix)

# Testing
make test                # All tests with coverage
make test-unit           # Unit tests only
make test-integration    # Integration tests only

# Pre-commit (fast)
make pre-commit-fast     # Only staged files

# Pre-commit (comprehensive, like CI)
make pre-commit-ci       # All files, all hooks
```

### Simulating CI Locally

```bash
# 1. Lint checks
black --check --line-length=100 .
isort --check --profile=black --line-length=100 .
flake8 --max-line-length=100 --extend-ignore=E203,W503 .
mypy --config-file=mypy.ini .

# 2. Test with coverage
pytest --cov=. --cov-report=term-missing --cov-fail-under=80

# 3. Docker build
docker build -t pulsewatch:test .
docker run --rm pulsewatch:test python --version
```

## Branch Protection

### Recommended Settings

To enforce CI checks before merging:

1. Go to: **Settings → Branches → Branch protection rules**
2. Add rule for `main` branch:
   - ✅ Require status checks to pass before merging
   - ✅ Require branches to be up to date before merging
   - Select required checks:
     - `Lint (Python 3.12)`
     - `Test (Python 3.11)`
     - `Test (Python 3.12)`
     - `Docker Build`
     - `CI Success`
   - ✅ Require conversation resolution before merging
   - ✅ Do not allow bypassing the above settings

3. Repeat for `develop` branch (if using GitFlow)

### Testing Branch Protection

```bash
# Create test branch
git checkout -b test/ci-validation

# Make a change that fails lint
echo "bad_formatting=1" >> test.py
git add test.py
git commit -m "test: intentional lint failure"
git push origin test/ci-validation

# Create PR and verify CI blocks merge
```

## Troubleshooting

### Lint Job Fails

**Black formatting errors**:
```bash
# Fix locally
make format
git add .
git commit --amend --no-edit
git push --force-with-lease
```

**Flake8 violations**:
```bash
# Check specific errors
flake8 --max-line-length=100 --extend-ignore=E203,W503 .

# Fix and commit
git add .
git commit -m "fix: resolve flake8 violations"
git push
```

### Test Job Fails

**Database connection errors**:
- Check MySQL service is healthy (wait step should handle this)
- Verify `DATABASE_URL` in workflow matches service config

**Coverage too low**:
```bash
# Check coverage locally
pytest --cov=. --cov-report=term-missing

# Add tests to increase coverage
# Commit and push
```

**Test failures**:
```bash
# Run specific test locally
pytest tests/path/to/test.py::test_name -v

# Fix and commit
```

### Docker Job Fails

**Build errors**:
```bash
# Test locally
docker build -t pulsewatch:test .

# Check Dockerfile syntax
# Fix and commit
```

**Runtime errors**:
```bash
# Test image
docker run --rm pulsewatch:test python --version
docker run --rm pulsewatch:test python manage.py check

# Fix dependencies or Dockerfile
```

### Re-running Failed Jobs

1. Go to **Actions** tab
2. Click on the failed workflow run
3. Click **Re-run jobs** dropdown
4. Select:
   - **Re-run all jobs**: Retry everything
   - **Re-run failed jobs**: Only retry failures

## Performance

### Typical Pipeline Duration

**Success scenario**:
- Lint: ~2-3 minutes
- Test (3.11): ~5-8 minutes
- Test (3.12): ~5-8 minutes
- Docker: ~3-5 minutes
- Security: ~3-4 minutes

**Total (parallel)**: ~8-10 minutes

**Total (if serial)**: ~25-30 minutes

Jobs run in parallel when possible, so total time is dominated by the slowest job (usually Test).

### Optimization Tips

1. **Use cache effectively**: Dependencies cached automatically
2. **Fail fast**: Set `fail-fast: false` only where needed
3. **Selective triggers**: Don't run on all branches if not needed
4. **Conditional steps**: Use `if` conditions to skip unnecessary steps

## Future Enhancements

- [ ] Add deployment jobs for staging/production
- [ ] Integrate with SonarQube for code quality metrics
- [ ] Add performance testing job
- [ ] Enable automatic dependency updates (Dependabot)
- [ ] Add Docker image scanning (Trivy, Snyk)
- [ ] Publish Docker images to registry
- [ ] Add E2E tests with Playwright/Cypress
- [ ] Enable matrix testing with different databases
- [ ] Add notification integrations (Slack, Discord)

## Resources

- [GitHub Actions Documentation](https://docs.github.com/en/actions)
- [Service Containers Guide](https://docs.github.com/en/actions/using-containerized-services)
- [Workflow Syntax](https://docs.github.com/en/actions/reference/workflow-syntax-for-github-actions)
- [Branch Protection Rules](https://docs.github.com/en/repositories/configuring-branches-and-merges-in-your-repository/defining-the-mergeability-of-pull-requests/about-protected-branches)
